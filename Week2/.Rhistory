install.packages("package")
ggplot(data = diamonds, aes(x = cut)) +
geom_bar(fill = "lightblue", colour = "black")
library(ggplot2)
install.packages("package")
diamonds
ggplot(data = diamonds, aes(x = price)) +
geom_histogram()
install.packages("vioplots")
install.packages("Diamonds")
install.packages("ggplot2")
install.packages("ggplot2")
knitr::opts_chunk$set(echo = TRUE)
library("ggplot2")
txhousing
ggplot(data = txhousing, aes(x = cut)) +
geom_bar(fill = "lightblue", colour = "black")
ggplot(data = txhousing, aes(x = sales)) +
+     geom_bar(fill = "lightblue", colour = "black")
ggplot(data = txhousing, aes(x = sales)) +
+     geom_bar(fill = "lightblue", colour = "black")
ggplot(data = txhousing, aes(x = sales)) + geom_bar(fill = "lightblue", colour = "black")
ggplot(data = txhousing, aes (x = volume)) + geom_histogram()
ggplot(data = txhousing, aes(x = inventory, y=volume)) + geom_point()
knitr::opts_chunk$set(echo = TRUE)
library("ggplot2")
economics
ggplot(data = economics, aes(x = pce)) +
geom_bar(fill = "lightblue", colour = "black")
ggplot(data = economics, aes(x =date)) +
geom_bar(fill = "lightblue", colour = "black")
knitr::opts_chunk$set(echo = TRUE)
library("ggplot2")
msleep
ggplot(data = msleep, aes(x =conservation)) +
geom_bar(fill = "lightblue", colour = "black")
ggplot(data = msleep, aes(x = sleep_total)) +
geom_histogram()
ggplot(data = msleep, aes(x = awake)) +geom_histogram()
ggplot(data = msleep, aes(x = brainwt)) +geom_histogram()
ggplot(data = msleep, aes(x =brainwt, y=sleep_cycle)) +
geom_point()
ggplot(msleep, aes(x=order, y=sleep_cycle)) +
geom_boxplot()
library(ggplot2)
library(GGally)
library(scales)
library(memisc)
ggplot(data = msleep, aes(x = sleep_total)) +geom_histogram()
plot(pressure)
plot(pressure)
msleep
knitr::opts_chunk$set(echo = TRUE)
library("ggplot2")
msleep
ggplot(data = msleep, aes(x =conservation)) +
geom_bar(fill = "lightblue", colour = "black")
ggplot(data = msleep, aes(x = sleep_total)) +geom_histogram()
ggplot(data = msleep, aes(x =brainwt, y=sleep_cycle)) +
geom_point()
ggplot(msleep, aes(x=order, y=sleep_cycle)) +
geom_boxplot()
library(ggplot2)
library(GGally)
library(scales)
library(memisc)
> install.packages("GGally")
install.packages("GGally")
install.packages(memisc)
install.packages("memisc")
library(memisc)
knitr::opts_chunk$set(echo = TRUE)
library("ggplot2")
msleep
knitr::opts_chunk$set(echo = TRUE)
library("ggplot2")
msleep
knitr::opts_chunk$set(echo = TRUE)
library("ggplot2")
msleep
knitr::opts_chunk$set(echo = TRUE)
library("ggplot2")
msleep
plot(pressure)
knitr::opts_chunk$set(echo = TRUE)
library("ggplot")
knitr::opts_chunk$set(echo = TRUE)
library("ggplot")
knitr::opts_chunk$set(echo = TRUE)
library("ggplot")
knitr::opts_chunk$set(echo = TRUE)
library("ggplot2")
msleep
setwd("~/Documents/GitHub/2018-Summer-CSX-RProject/Week2")
#https://www.ptt.cc/bbs/Gossiping/index.html
id = c(1:10)
URL = paste()("https://www.ptt.cc/bbs/Gossiping/index"), id, ".html"
filename = paste()(id, ".txt"_)
pttTestFunction(URL[1], filename[1])
mapply(pttTestFunction,
URL = URL, filename = filename)
}
href  = html_attr(title, "href")
url  = paste0("https://www.ptt.cc", x)
tag  = html_node(read_html(url), 'div#main-content.bbs-screen.bbs-content')
text = toUTF8(html_text(tag))
getContent <- function(x) {
url  = paste0("https://www.ptt.cc", x)
tag  = html_node(read_html(url), 'div#main-content.bbs-screen.bbs-content')
text = toUTF8(html_text(tag))
}
#getContent(data$href[1])
allText = sapply(data$href, getContent)
allText
#out <- file(filename, "w", encoding="BIG-5")
write.table(allText, filename)
#close(out)
}
mapply(pttTestFunction,
URL = URL, filename = filename)
install.packages("NLP")
install.packages(tm)
install.packages("jiebaRD")
install.packages("jiebaR")
install.packages("RColorBrewer")
install.packages("wordcloud")
instaall package(rvest)
install.packages("tmcn")
install.packages("tm")
install.packages("rvest")
knitr::opts_chunk$set(echo = TRUE)
docs <- tm_map(docs, toSpace, "我")
docs <- tm_map(docs, toSpace, "我")docs <- tm_map(docs, toSpace, "是")
docs <- tm_map(docs, toSpace, "我")docs <- tm_map(docs, toSpace, "看板")
knitr::opts_chunk$set(echo = TRUE)
source('pttTestFunction.R')
id = c(1:10)
URL = paste0("https://www.ptt.cc/bbs/Food/index", id, ".html")
filename = paste0(id, ".txt")
pttTestFunction(URL[1], filename[1])
mapply(pttTestFunction,
URL = URL, filename = filename)
docs
rm(list=ls(all.names = TRUE))
library(NLP)
library(tm)
library(jiebaRD)
library(jiebaR)
library(RColorBrewer)
library(wordcloud)
filenames <- list.files(getwd(), pattern="*.txt")
files <- lapply(filenames, readLines)
docs <- Corpus(VectorSource(files))
toSpace <- content_transformer(function(x, pattern) {
return (gsub(pattern, " ", x))
}
)
docs <- tm_map(docs, toSpace, "※")
docs <- tm_map(docs, toSpace, "◆")
docs <- tm_map(docs, toSpace, "‧")
docs <- tm_map(docs, toSpace, "的")
docs <- tm_map(docs, toSpace, "了")
docs <- tm_map(docs, toSpace, "有")
docs <- tm_map(docs, toSpace, "就")
docs <- tm_map(docs, toSpace, "也")
docs <- tm_map(docs, toSpace, "很")
docs <- tm_map(docs, toSpace, "是")
docs <- tm_map(docs, toSpace, "我")
docs <- tm_map(docs, toSpace, "看板")
docs <- tm_map(docs, toSpace, "作者")
docs <- tm_map(docs, toSpace, "發信站")
docs <- tm_map(docs, toSpace, "批踢踢實業坊")
docs <- tm_map(docs, toSpace, "[a-zA-Z]")
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, stripWhitespace)
docs
mixseg = worker()
jieba_tokenizer=function(d){
unlist(segment(d[[1]],mixseg))
}
seg = lapply(docs, jieba_tokenizer)
freqFrame = as.data.frame(table(unlist(seg)))
freqFrame = freqFrame[order(freqFrame$Freq,decreasing=TRUE), ]
library(knitr)
kable(head(freqFrame), format = "markdown")
wordcloud(freqFrame$Var1,freqFrame$Freq,
scale=c(5,0.1),min.freq=50,max.words=150,
random.order=TRUE, random.color=FALSE,
rot.per=.1, colors=brewer.pal(8, "Dark2"),
ordered.colors=FALSE,use.r.layout=FALSE,
fixed.asp=TRUE)
wordcloud(freqFrame$Var1,freqFrame$Freq,
scale=c(5,0.1),min.freq=50,max.words=150,
random.order=TRUE, random.color=FALSE,
rot.per=.1, colors=brewer.pal(8, "Dark2"),
ordered.colors=FALSE,use.r.layout=FALSE,
fixed.asp=TRUE)
mixseg = worker()
source('pttTestFunction.R')
id = c(1:10)
URL = paste0("https://www.ptt.cc/bbs/Food/index", id, ".html")
filename = paste0(id, ".txt")
pttTestFunction(URL[1], filename[1])
mapply(pttTestFunction,
URL = URL, filename = filename)
rm(list=ls(all.names = TRUE))
library(NLP)
library(tm)
library(jiebaRD)
library(jiebaR)
library(RColorBrewer)
library(wordcloud)
filenames <- list.files(getwd(), pattern="*.txt")
files <- lapply(filenames, readLines)
docs <- Corpus(VectorSource(files))
toSpace <- content_transformer(function(x, pattern) {
return (gsub(pattern, " ", x))
}
)
docs <- tm_map(docs, toSpace, "※")
docs <- tm_map(docs, toSpace, "◆")
docs <- tm_map(docs, toSpace, "‧")
docs <- tm_map(docs, toSpace, "的")
docs <- tm_map(docs, toSpace, "了")
docs <- tm_map(docs, toSpace, "有")
docs <- tm_map(docs, toSpace, "就")
docs <- tm_map(docs, toSpace, "也")
docs <- tm_map(docs, toSpace, "很")
docs <- tm_map(docs, toSpace, "是")
docs <- tm_map(docs, toSpace, "我")
docs <- tm_map(docs, toSpace, "看板")
docs <- tm_map(docs, toSpace, "作者")
docs <- tm_map(docs, toSpace, "發信站")
docs <- tm_map(docs, toSpace, "批踢踢實業坊")
docs <- tm_map(docs, toSpace, "[a-zA-Z]")
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, stripWhitespace)
docs
mixseg = worker()
jieba_tokenizer=function(d){
unlist(segment(d[[1]],mixseg))
}
seg = lapply(docs, jieba_tokenizer)
freqFrame = as.data.frame(table(unlist(seg)))
freqFrame = freqFrame[order(freqFrame$Freq,decreasing=TRUE), ]
library(knitr)
kable(head(freqFrame), format = "markdown")
wordcloud(freqFrame$Var1,freqFrame$Freq,
scale=c(5,0.1),min.freq=50,max.words=150,
random.order=TRUE, random.color=FALSE,
rot.per=.1, colors=brewer.pal(8, "Dark2"),
ordered.colors=FALSE,use.r.layout=FALSE,
fixed.asp=TRUE)
wordcloud(freqFrame$Var1,freqFrame$Freq,
scale=c(5,0.1),min.freq=50,max.words=150,
random.order=TRUE, random.color=FALSE,
rot.per=.1, colors=brewer.pal(8, "Dark2"),
ordered.colors=FALSE,use.r.layout=FALSE,
fixed.asp=TRUE, encoding=UTF-8)
source('pttTestFunction.R')
id = c(1:10)
URL = paste0("https://www.ptt.cc/bbs/Food/index", id, ".html")
filename = paste0(id, ".txt")
pttTestFunction(URL[1], filename[1])
mapply(pttTestFunction,
URL = URL, filename = filename)
rm(list=ls(all.names = TRUE))
library(NLP)
library(tm)
library(jiebaRD)
library(jiebaR)
library(RColorBrewer)
library(wordcloud)
filenames <- list.files(getwd(), pattern="*.txt")
files <- lapply(filenames, readLines)
docs <- Corpus(VectorSource(files))
toSpace <- content_transformer(function(x, pattern) {
return (gsub(pattern, " ", x))
}
)
docs <- tm_map(docs, toSpace, "※")
docs <- tm_map(docs, toSpace, "◆")
docs <- tm_map(docs, toSpace, "‧")
docs <- tm_map(docs, toSpace, "的")
docs <- tm_map(docs, toSpace, "了")
docs <- tm_map(docs, toSpace, "有")
docs <- tm_map(docs, toSpace, "就")
docs <- tm_map(docs, toSpace, "也")
docs <- tm_map(docs, toSpace, "很")
docs <- tm_map(docs, toSpace, "是")
docs <- tm_map(docs, toSpace, "我")
docs <- tm_map(docs, toSpace, "看板")
docs <- tm_map(docs, toSpace, "作者")
docs <- tm_map(docs, toSpace, "發信站")
docs <- tm_map(docs, toSpace, "批踢踢實業坊")
docs <- tm_map(docs, toSpace, "[a-zA-Z]")
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, stripWhitespace)
docs
mixseg = worker()
jieba_tokenizer=function(d){
unlist(segment(d[[1]],mixseg))
}
seg = lapply(docs, jieba_tokenizer)
freqFrame = as.data.frame(table(unlist(seg)))
freqFrame = freqFrame[order(freqFrame$Freq,decreasing=TRUE), ]
library(knitr)
kable(head(freqFrame), format = "markdown")
wordcloud(freqFrame$Var1,freqFrame$Freq,
scale=c(5,0.1),min.freq=50,max.words=150,
random.order=TRUE, random.color=FALSE,
rot.per=.1, colors=brewer.pal(8, "Dark2"),
ordered.colors=FALSE,use.r.layout=FALSE,
fixed.asp=TRUE, encoding=UTF-8)
wordcloud(freqFrame$Var1,freqFrame$Freq,
scale=c(5,0.1),min.freq=50,max.words=150,
random.order=TRUE, random.color=FALSE,
rot.per=.1, colors=brewer.pal(8, "Dark2"),
ordered.colors=FALSE,use.r.layout=FALSE,
fixed.asp=TRUE)
source('pttTestFunction.R')
id = c(1:10)
URL = paste0("https://www.ptt.cc/bbs/Food/index", id, ".html")
filename = paste0(id, ".txt")
pttTestFunction(URL[1], filename[1])
mapply(pttTestFunction,
URL = URL, filename = filename)
knitr::opts_chunk$set(echo = TRUE)
source('pttTestFunction.R')
id = c(1:10)
URL = paste0("https://www.ptt.cc/bbs/Food/index", id, ".html")
filename = paste0(id, ".txt")
pttTestFunction(URL[1], filename[1])
mapply(pttTestFunction,
URL = URL, filename = filename)
rm(list=ls(all.names = TRUE))
library(NLP)
library(tm)
library(jiebaRD)
library(jiebaR)
library(RColorBrewer)
library(wordcloud)
filenames <- list.files(getwd(), pattern="*.txt")
files <- lapply(filenames, readLines)
docs <- Corpus(VectorSource(files))
toSpace <- content_transformer(function(x, pattern) {
return (gsub(pattern, " ", x))
}
)
docs <- tm_map(docs, toSpace, "※")
docs <- tm_map(docs, toSpace, "◆")
docs <- tm_map(docs, toSpace, "‧")
docs <- tm_map(docs, toSpace, "的")
docs <- tm_map(docs, toSpace, "了")
docs <- tm_map(docs, toSpace, "有")
docs <- tm_map(docs, toSpace, "就")
docs <- tm_map(docs, toSpace, "也")
docs <- tm_map(docs, toSpace, "很")
docs <- tm_map(docs, toSpace, "是")
docs <- tm_map(docs, toSpace, "我")
docs <- tm_map(docs, toSpace, "看板")
docs <- tm_map(docs, toSpace, "作者")
docs <- tm_map(docs, toSpace, "發信站")
docs <- tm_map(docs, toSpace, "批踢踢實業坊")
docs <- tm_map(docs, toSpace, "[a-zA-Z]")
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, stripWhitespace)
docs
mixseg = worker()
jieba_tokenizer=function(d){
unlist(segment(d[[1]],mixseg))
}
seg = lapply(docs, jieba_tokenizer)
freqFrame = as.data.frame(table(unlist(seg)))
freqFrame = freqFrame[order(freqFrame$Freq,decreasing=TRUE), ]
library(knitr)
kable(head(freqFrame), format = "markdown")
wordcloud(freqFrame$Var1,freqFrame$Freq,
scale=c(5,0.1),min.freq=50,max.words=150,
random.order=TRUE, random.color=FALSE,
rot.per=.1, colors=brewer.pal(8, "Dark2"),
ordered.colors=FALSE,use.r.layout=FALSE,
fixed.asp=TRUE)
